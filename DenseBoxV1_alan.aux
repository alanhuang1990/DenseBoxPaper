\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{dalal2005histograms}
\citation{lowe2004distinctive}
\citation{cinbis2013segmentation}
\citation{felzenszwalb2010object}
\citation{girshick2014rich}
\citation{girshick2015fast}
\citation{ren2015faster}
\citation{YOLO}
\citation{LencV15}
\citation{farfade2015multi}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{long2014fully}
\citation{faceevaluation15}
\citation{Geiger2012CVPR}
\citation{vaillant1994original}
\citation{rowley1998neural}
\citation{rowley1998rotation}
\citation{ouyang2014deepid}
\citation{li2015convolutional}
\citation{erhan2014scalable}
\citation{girshick2015fast}
\citation{farfade2015multi}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}DenseBoxNet for Detection }{2}{section.3}}
\newlabel{sec:model}{{3}{2}{DenseBoxNet for Detection}{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {The DenseBoxNet Detection Pipeline.} 1) Image pyramid is fed to the network. 2) After several layer of convolution and pooling, upsampling feature map back and apply convolution layers to get final output. 3) Convert output feature map to bounding boxes , and apply non-maximum suppression to all bounding boxes over the threshold. }}{2}{figure.1}}
\newlabel{fig:fig_overview}{{1}{2}{\textbf {The DenseBoxNet Detection Pipeline.} 1) Image pyramid is fed to the network. 2) After several layer of convolution and pooling, upsampling feature map back and apply convolution layers to get final output. 3) Convert output feature map to bounding boxes , and apply non-maximum suppression to all bounding boxes over the threshold}{figure.1}{}}
\citation{pinheiro2015learning}
\citation{simonyan2014very}
\citation{bertasius2014deepedge}
\citation{liu2015parsenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Ground Truth Generation }{3}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {The Ground Truth Map in Training .} The left image is the input patch, and the right one is its ground truth map. }}{3}{figure.2}}
\newlabel{fig:fig_gt}{{2}{3}{\textbf {The Ground Truth Map in Training .} The left image is the input patch, and the right one is its ground truth map}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Model Design }{3}{subsection.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Network architecture of DenseBoxNet.} The rectangles with red names contain learnable parameters. }}{4}{figure.3}}
\newlabel{fig:fig_net}{{3}{4}{\textbf {Network architecture of DenseBoxNet.} The rectangles with red names contain learnable parameters}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Multi-Task Training.}{4}{subsection.3.3}}
\newlabel{sec:training}{{3.3}{4}{Multi-Task Training}{subsection.3.3}{}}
\newlabel{eq:eq_cls_loss}{{1}{4}{Multi-Task Training}{equation.3.1}{}}
\newlabel{eq:eq_loc_loss}{{2}{4}{Multi-Task Training}{equation.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Balance Sampling.}{4}{subsubsection.3.3.1}}
\citation{tompson2014joint}
\newlabel{eq:eq_mask}{{3}{5}{Balance Sampling}{equation.3.3}{}}
\newlabel{eq:eq_det_loss}{{4}{5}{Balance Sampling}{equation.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Refine with Landmark Localization.}{5}{subsection.3.4}}
\citation{vaillant1994original}
\citation{rowley1998neural}
\citation{sermanet2013overfeat}
\citation{krizhevsky2012imagenet}
\citation{farfade2015multi}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Top: } The pipeline of DenseBoxNet with landmark localization. \textbf  {Bottom: } The network structure for landmark localization. }}{6}{figure.4}}
\newlabel{fig:fig_refine}{{4}{6}{\textbf {Top: } The pipeline of DenseBoxNet with landmark localization. \textbf {Bottom: } The network structure for landmark localization}{figure.4}{}}
\newlabel{eq:eq_full_loss}{{5}{6}{Refine with Landmark Localization}{equation.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Comparison }{6}{subsection.3.5}}
\citation{ren2015faster}
\citation{erhan2014scalable}
\citation{ren2015faster}
\citation{YOLO}
\citation{faceevaluation15}
\citation{Geiger2012CVPR}
\citation{jain2010fddb}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{7}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1} MALF Detection Task}{7}{subsection.4.1}}
\citation{li2014integrating}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Left: } 72 landmarks for face. \textbf  {Right: } 8 landmarks for car. }}{8}{figure.5}}
\newlabel{fig:fig_landmark}{{5}{8}{\textbf {Left: } 72 landmarks for face. \textbf {Right: } 8 landmarks for car}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  \textbf  {Result on MALF dataset. } (a) Comparison of different versions of DenseBoxNet; (b)The curves and mean recall rate of DenseBoxNet and other methods; }}{8}{figure.6}}
\newlabel{fig:fig_malf}{{6}{8}{\textbf {Result on MALF dataset. } (a) Comparison of different versions of DenseBoxNet; (b)The curves and mean recall rate of DenseBoxNet and other methods;}{figure.6}{}}
\citation{long2015accurate}
\citation{li2014integrating}
\citation{xiang2015data}
\citation{szegedy2014going}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2} KITTI Car Detection Task}{9}{subsection.4.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The Averate Presision on KITTI Car Detection Task}}{9}{table.1}}
\newlabel{tab:tab_kitti}{{1}{9}{The Averate Presision on KITTI Car Detection Task}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{9}{section.5}}
\bibstyle{abbrv}
\bibdata{section/references.bib}
\bibcite{bertasius2014deepedge}{1}
\bibcite{cinbis2013segmentation}{2}
\bibcite{dalal2005histograms}{3}
\bibcite{erhan2014scalable}{4}
\bibcite{farfade2015multi}{5}
\bibcite{felzenszwalb2010object}{6}
\bibcite{Geiger2012CVPR}{7}
\bibcite{girshick2015fast}{8}
\bibcite{girshick2014rich}{9}
\bibcite{jain2010fddb}{10}
\bibcite{krizhevsky2012imagenet}{11}
\bibcite{LencV15}{12}
\bibcite{li2014integrating}{13}
\bibcite{li2015convolutional}{14}
\bibcite{liu2015parsenet}{15}
\bibcite{long2015accurate}{16}
\bibcite{long2014fully}{17}
\bibcite{lowe2004distinctive}{18}
\bibcite{ouyang2014deepid}{19}
\bibcite{pinheiro2015learning}{20}
\bibcite{YOLO}{21}
\bibcite{ren2015faster}{22}
\bibcite{rowley1998neural}{23}
\bibcite{rowley1998rotation}{24}
\bibcite{sermanet2013overfeat}{25}
\bibcite{simonyan2014very}{26}
\bibcite{szegedy2014going}{27}
\bibcite{tompson2014joint}{28}
\bibcite{vaillant1994original}{29}
\bibcite{xiang2015data}{30}
\bibcite{faceevaluation15}{31}
