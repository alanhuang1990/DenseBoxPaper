\section{Introduction}

As one of the core problems in image understanding, object detection has some significant breakthrough recent years after the widely applied deep convolutional neural networks. Before the success of convolutional neural networks, the best performing detectors in many benchmarks were based on a combination of handcrafted image feature such as HOG~\cite{dalal2005histograms} , SIFT~\cite{lowe2004distinctive} , and the Fisher vector~\cite{cinbis2013segmentation} , etc. These systems such as deformable part-based models (DPM)~\cite{felzenszwalb2010object} use sliding window framework to apply classifier at every object locations and scales. Recently, the convolutional neural network based methods such as R-CNN~\cite{girshick2014rich,girshick2015fast} bring a revolution on the field of object detection , providing a remarkable gain in detection accuracy compared to classic sliding window approaches. Conceptually, R-CNN contains two phases. First, region proposal methods are used to generate potential bounding boxes in the image. Then, a convolutional classifier is applied to each proposed bounding box. 

However, the different stages in R-CNN pipeline cannot be optimized jointly, and to classify thousands of proposal bounding boxes of one image, it usually requires half a minute. The second issue has been solved in the latest incarnation of R-CNN, the Faster R-CNN~\cite{ren2015faster} which shares the convolutional feature computation among different regions. Then the proposal generation becomes the new bottleneck. Recently some methods try to solve the first issue by one of the following two ways: 1) The Faster-R-CNN trains a region proposal network shared with CNN classifier; 2) YOLO~\cite{YOLO}  presents a single network end-to-end optimized directly on detection performance, and Lenc et al.~\cite{LencV15} proposed a simplified SPP-CNN~\cite{} that does not need proposal generation. All of them focus on acceleration of testing, and developing an end-to-end framework for detection. 

In this work, we focus on one question: To what extent can an one-stage CNN-based detection system perform? Although similar to YOLO~\cite{YOLO}, MultiBox~\cite{} and OverFeat~\cite{sermanet2013overfeat}, our system is more carefully designed for a set of specific problems such as face detection and car detection. Unlike general object detection in PASCAL VOC or ImageNet, the target objects like faces and cars could be very small but crucial to real world application ({\em i.e.} self-driving car). However, general proposal based detection methods could fail due to the the small resolution of objects. Our system is designed end-to-end to detect objects over all possible locations and scales in an image. 

To this end, we present a novel fully convolutional neural network based object detector, called DenseBox, that does not require proposal generation and is able to be optimized end-to-end during training. We further integrate landmark localization task into the system through multi-task learning, and demonstrate that landmark localization is helpful and crucial for object detection. Experimental results show that our method results in the state-of-the-art performance on MALF(Multi-Attribute Labelled Faces)~\cite{faceevaluation15} detection dataset and KITTI~\cite{Geiger2012CVPR} car detection dataset, suggesting that the purely fully convolutional networks for object detection can work very well when we design and train carefully. 

\section{Related Work}

The literature on object detection is vast, and in this section we will focus on approaches exploiting class-agnostic ideas and addressing scalability.

Object detection long history.

Sliding window based detection.

R-CNN based detection.

Convolutional Neural Networks.

Finally, we capitalize on the recent advances in Deep Learning, most noticeably the work by Krizhevsky et al. [11]. We extend their bounding box regression approach for detection to the case of handling multiple objects in a scalable manner. DNN-based regression applied to object masks has been investigated by Szegedy et al. [15]. This last approach achieves state-of-art detection performance on VOC2007 but does not scale up to multiple classes due to the cost of a single mask regression: in that setup, one needs to execute 5 networks per class at inference time, which is not scalable for most real-world applications.

Several recent papers have proposed ways of using deep networks for locating class-specific or class-agnostic bounding boxes [20, 17, 3, 19]. In the OverFeat method [17], a 4-d output fc layer (for each or all classes) is trained to predict the box coordinates for the localization task (which assumes a single object). The fc layer is then turned into a conv layer for detecting multiple class- specific objects. The MultiBox methods [3, 19] generate region proposals from a network whose last fc layer simultaneously predicts multiple (e.g., 800) boxes, which are used for R-CNN [6] object detection. Their proposal network is applied on a single image or multiple large image crops (e.g., 224×224) [19]. We discuss OverFeat and MultiBox in more depth later in context with our method.
Shared computation of convolutions [17, 7, 2, 5] has been attracting increasing attention for efficient, yet accurate, visual recognition. The OverFeat paper [17] computes conv features from an image pyramid for classification, localization, and detection. Adaptively-sized pooling [7] on shared conv feature maps is proposed for efficient region-based object detection [7, 15] and semantic segmenta- tion [2]. Fast R-CNN [5] enables end-to-end training of adaptive pooling on shared conv features and shows compelling accuracy and speed.

Several recent papers have proposed ways of using deep networks for locating class-specific or class-agnostic bounding boxes [20, 17, 3, 19]. In the OverFeat method [17], a 4-d output fc layer (for each or all classes) is trained to predict the box coordinates for the localization task (which assumes a single object). The fc layer is then turned into a conv layer for detecting multiple class- specific objects. The MultiBox methods [3, 19] generate region proposals from a network whose last fc layer simultaneously predicts multiple (e.g., 800) boxes, which are used for R-CNN [6] object detection. Their proposal network is applied on a single image or multiple large image crops (e.g., 224×224) [19]. We discuss OverFeat and MultiBox in more depth later in context with our method.
Shared computation of convolutions [17, 7, 2, 5] has been attracting increasing attention for efficient, yet accurate, visual recognition. The OverFeat paper [17] computes conv features from an image pyramid for classification, localization, and detection. Adaptively-sized pooling [7] on shared conv feature maps is proposed for efficient region-based object detection [7, 15] and semantic segmenta- tion [2]. Fast R-CNN [5] enables end-to-end training of adaptive pooling on shared conv features and shows compelling accuracy and speed.

% This is the new version, which reviewed both nn based detection in the 1990s and the current RCNN.

The application of neural networks for detection tasks such as face detection has a long history. The first work may date back to early in 1994 when Vaillant et al.\cite{vaillant1994original} proposed to train a convolutional neural network to detect face in image window.  Later in 1996 and 1998 Rowley et al.\cite{rowley1998neural,rowley1998rotation} presented many neural network based face detection system to detect upright frontal face in image pyramid. There is no way to compare the performance of those ancient detectors with today’s detection systems on face detection benchmarks. Even so, they are still worth revisiting, as we find many similarities in design with our DenseBox. 

Currently, most state-of-the-art object detection approaches\cite{ouyang2014deepid, li2015convolutional, erhan2014scalable,girshick2015fast}rely on R-CNN, which divides detection into two steps: salient object proposal generation and region proposal classification. Several recent works such as YOLO and Faster R-CNN have jointed region proposal generation with classifier in one stage or two stages. It is pointed out by \cite{farfade2015multi} that R-CNN with general proposal methods designed for general object detection could results in inferior performance in detection task such as face detection, due to loss recall for small-sized faces and faces in complex appearance variations. They share similarities with our method, and we will discuss them with our method in more detail in later context.  

 
