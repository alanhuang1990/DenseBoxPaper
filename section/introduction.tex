\section{Introduction}

Our day-to-day lives are abound with instances of object detection. Checking for nearby cars during driving, finding a person, and localizing a familiar face are all examples of object detection. Object detection is one of the core problems in computer vision. Before the success of convolutional neural networks (CNNs)~\cite{krizhevsky2012imagenet}, object detection is usually addressed by sliding window based methods~\cite{felzenszwalb2010object, viola2004robust} that apply classifiers on handcrafted features~\cite{dalal2005histograms, lowe2004distinctive, cinbis2013segmentation} extracted at all possible locations and scales of images. Recently, the fully convolutional neural network (FCN)~\cite{long2014fully} based methods~\cite{sermanet2013overfeat, erhan2014scalable, YOLO} bring a revolution to the field of object detection. These FCN frameworks also follow a sliding window fashion, but their end-to-end approaches of learning model parameters and image features from scratch significantly improves detection performance. 

R-CNN~\cite{girshick2014rich, girshick2015fast} further improves the accruacy on object detection beyond FCN based methods. Conceptually, R-CNN contains two phases. The first phase uses region proposal methods to generate all the potential bounding box candidates in the image. Then the second phase applies a CNN classifier to discriminate objects against background for every proposal. Although R-CNN becomes the new state-of-the-art system for general object detection~\cite{everingham2010pascal, russakovsky2014imagenet}, it is very hard to detect small objects~\cite{pepik2015holding} such as human faces and far-away cars, since the low resolution and lack of contexts in each candidate box significantly decrease the classification accuracy on faces and cars. Moreover, the two different stages in the R-CNN pipeline cannot be optimized jointly, leaving the trouble for applying end-to-end training on R-CNN. 

In this work, we focus on one question: To what extent can an one-stage FCN perform on object detection? To this end, we present a novel FCN based object detector, DenseBox, that does not require proposal generation and is able to be optimized end-to-end during training. Although similar to many existing FCN detection frameworks~\cite{sermanet2013overfeat, erhan2014scalable, YOLO}, DenseBox is more carefully designed to detect objects under different scales and occlusions. We train DenseBox completely from scratch and apply careful hard negative mining techniques to boostrap the detection performance. To make it even better, we further integrate landmark localization task into the system through joint multi-task learning~\cite{bengio2013representation}. To verify the usefulness of landmark localization, we manually annotate a set of keypoints for the KITTI car detection dataset~\cite{Geiger2012CVPR} and will release it afterward. 

Our contribution is two-fold. First, we demonstrate that a single fully convolutional neural network, if designed and optimized well, can detect different objects extremely accurately and efficiently. Second, we show that when incorporating with landmark localization through multi-task learning, DenseBox further improves object detection accuracy. We present experimental results on public benchmark datasets including MALF (Multi-Attribute Labeled Faces) face detection~\cite{faceevaluation15} and KITTI car detection~\cite{Geiger2012CVPR}, that indicate our DenseBox is the state-of-the-art system for object detection, outperforming R-CNN while being orders of magnitude faster.

%As one of the core problems in computer vision, object detection has some significant breakthrough recent years after the widely applied deep convolutional neural networks. Before the success of convolutional neural networks, the best performing detectors in many benchmarks were based on a combination of handcrafted image feature such as HOG~\cite{dalal2005histograms} , SIFT~\cite{lowe2004distinctive} , and the Fisher vector~\cite{cinbis2013segmentation} , etc. These systems such as deformable part-based models (DPM)~\cite{felzenszwalb2010object} use sliding window framework to apply classifier at every object location and scale. Recently, the convolutional neural network based methods such as R-CNN~\cite{girshick2014rich,girshick2015fast} bring a revolution on the field of object detection , providing a remarkable gain in detection accuracy compared to classic sliding window approaches. Conceptually, R-CNN contains two phases. First, region proposal methods are used to generate potential bounding boxes in the image. Then, a convolutional classifier is applied to each proposed bounding box. 

%However, the different stages in R-CNN pipeline cannot be optimized jointly, and to classify thousands of proposal bounding boxes of one image, it usually requires half a minute. The second issue has been solved in the latest incarnation of R-CNN, the Faster R-CNN~\cite{ren2015faster} which shares the convolutional feature computation among different regions. Then the proposal generation becomes the new bottleneck. Recently some methods try to solve the first issue by one of the following two ways: 1) The Faster-R-CNN trains a region proposal network shared with CNN classifier; 2) YOLO~\cite{YOLO}  presents a single network end-to-end optimized directly on detection performance, and Lenc et al.~\cite{LencV15} proposed a simplified SPP-CNN~\cite{} that does not need proposal generation. All of them focus on acceleration of testing, and developing an end-to-end framework for detection. 

%In this work, we focus on one question: To what extent can an one-stage CNN-based detection system perform? Although similar to YOLO~\cite{YOLO}, MultiBox~\cite{} and OverFeat~\cite{sermanet2013overfeat}, our system is more carefully designed for a set of specific problems such as face detection and car detection. Unlike general object detection in PASCAL VOC or ImageNet, the target objects like faces and cars could be very small but crucial to real world applications ({\em i.e.} self-driving car). However, general proposal based detection methods could fail due to the the small resolution of objects. Our system is designed end-to-end to detect objects over all possible locations and scales in an image. 

%To this end, we present a novel fully convolutional neural network based object detector, called DenseBox, that does not require proposal generation and is able to be optimized end-to-end during training. We further integrate landmark localization task into the system through multi-task learning, and demonstrate that landmark localization is helpful and crucial for object detection. Experimental results show that our method results in the state-of-the-art performance on MALF(Multi-Attribute Labelled Faces)~\cite{faceevaluation15} detection dataset and KITTI~\cite{Geiger2012CVPR} car detection dataset, suggesting that the purely fully convolutional networks for object detection can work very well when we design and train carefully. 

\section{Related Work}

% Sliding window based object detection
% RCNN
% Multi-task learning
% End-to-end Convolutional Neural Net

The literature on object detection is vast, and in this section we will focus on approaches exploiting class-agnostic ideas and addressing scalability.

As one of the core problems in image understanding, object detection has some significant breakthrough recent years after the widely applied deep convolutional neural networks. Before the success of convolutional neural networks, the best performing detectors in many benchmarks were based on a combination of handcrafted image feature such as HOG~\cite{dalal2005histograms} , SIFT~\cite{lowe2004distinctive} , and the Fisher vector~\cite{cinbis2013segmentation} , etc. These systems such as deformable part-based models (DPM)~\cite{felzenszwalb2010object} use sliding window framework to apply classifier at every object location and scale. Recently, the convolutional neural network based methods such as R-CNN~\cite{girshick2014rich,girshick2015fast} bring a revolution on the field of object detection , providing a remarkable gain in detection accuracy compared to classic sliding window approaches. Conceptually, R-CNN contains two phases. First, region proposal methods are used to generate potential bounding boxes in the image. Then, a convolutional classifier is applied to each proposed bounding box. 

As one of the core problems in image understanding, object detection has some significant breakthrough recent years after the widely applied deep convolutional neural networks. Before the success of convolutional neural networks, the best performing detectors in many benchmarks were based on a combination of handcrafted image feature such as HOG~\cite{dalal2005histograms} , SIFT~\cite{lowe2004distinctive} , and the Fisher vector~\cite{cinbis2013segmentation} , etc. These systems such as deformable part-based models (DPM)~\cite{felzenszwalb2010object} use sliding window framework to apply classifier at every object locations and scales. Recently, the convolutional neural network based methods such as R-CNN~\cite{girshick2014rich,girshick2015fast} bring a revolution on the field of object detection , providing a remarkable gain in detection accuracy compared to classic sliding window approaches. Conceptually, R-CNN contains two phases. First, region proposal methods are used to generate potential bounding boxes in the image. Then, a convolutional classifier is applied to each proposed bounding box. 

Object detection long history.

Sliding window based detection.

R-CNN based detection.

Convolutional Neural Networks.

Finally, we capitalize on the recent advances in Deep Learning, most noticeably the work by Krizhevsky et al. [11]. We extend their bounding box regression approach for detection to the case of handling multiple objects in a scalable manner. DNN-based regression applied to object masks has been investigated by Szegedy et al. [15]. This last approach achieves state-of-art detection performance on VOC2007 but does not scale up to multiple classes due to the cost of a single mask regression: in that setup, one needs to execute 5 networks per class at inference time, which is not scalable for most real-world applications.

Several recent papers have proposed ways of using deep networks for locating class-specific or class-agnostic bounding boxes [20, 17, 3, 19]. In the OverFeat method [17], a 4-d output fc layer (for each or all classes) is trained to predict the box coordinates for the localization task (which assumes a single object). The fc layer is then turned into a conv layer for detecting multiple class- specific objects. The MultiBox methods [3, 19] generate region proposals from a network whose last fc layer simultaneously predicts multiple (e.g., 800) boxes, which are used for R-CNN [6] object detection. Their proposal network is applied on a single image or multiple large image crops (e.g., 224×224) [19]. We discuss OverFeat and MultiBox in more depth later in context with our method.
Shared computation of convolutions [17, 7, 2, 5] has been attracting increasing attention for efficient, yet accurate, visual recognition. The OverFeat paper [17] computes conv features from an image pyramid for classification, localization, and detection. Adaptively-sized pooling [7] on shared conv feature maps is proposed for efficient region-based object detection [7, 15] and semantic segmenta- tion [2]. Fast R-CNN [5] enables end-to-end training of adaptive pooling on shared conv features and shows compelling accuracy and speed.

Several recent papers have proposed ways of using deep networks for locating class-specific or class-agnostic bounding boxes [20, 17, 3, 19]. In the OverFeat method [17], a 4-d output fc layer (for each or all classes) is trained to predict the box coordinates for the localization task (which assumes a single object). The fc layer is then turned into a conv layer for detecting multiple class- specific objects. The MultiBox methods [3, 19] generate region proposals from a network whose last fc layer simultaneously predicts multiple (e.g., 800) boxes, which are used for R-CNN [6] object detection. Their proposal network is applied on a single image or multiple large image crops (e.g., 224×224) [19]. We discuss OverFeat and MultiBox in more depth later in context with our method.
Shared computation of convolutions [17, 7, 2, 5] has been attracting increasing attention for efficient, yet accurate, visual recognition. The OverFeat paper [17] computes conv features from an image pyramid for classification, localization, and detection. Adaptively-sized pooling [7] on shared conv feature maps is proposed for efficient region-based object detection [7, 15] and semantic segmenta- tion [2]. Fast R-CNN [5] enables end-to-end training of adaptive pooling on shared conv features and shows compelling accuracy and speed.

% This is the new version, which reviewed both nn based detection in the 1990s and the current RCNN.

The application of neural networks for detection tasks such as face detection has a long history. The first work may date back to early in 1994 when Vaillant et al.\cite{vaillant1994original} proposed to train a convolutional neural network to detect face in image window.  Later in 1996 and 1998 Rowley et al.\cite{rowley1998neural,rowley1998rotation} presented many neural network based face detection system to detect upright frontal face in image pyramid. There is no way to compare the performance of those ancient detectors with today’s detection systems on face detection benchmarks. Even so, they are still worth revisiting, as we find many similarities in design with our DenseBox. 

Currently, most state-of-the-art object detection approaches\cite{ouyang2014deepid, li2015convolutional, erhan2014scalable,girshick2015fast}rely on R-CNN, which divides detection into two steps: salient object proposal generation and region proposal classification. Several recent works such as YOLO and Faster R-CNN have jointed region proposal generation with classifier in one stage or two stages. It is pointed out by \cite{farfade2015multi} that R-CNN with general proposal methods designed for general object detection could results in inferior performance in detection task such as face detection, due to loss recall for small-sized faces and faces in complex appearance variations. They share similarities with our method, and we will discuss them with our method in more detail in later context.  

 
