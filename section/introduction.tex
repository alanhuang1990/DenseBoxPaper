\section{Introduction}
Our day-to-day lives are abound with instances of object detection. Checking for nearby cars during driving, finding a person, and localizing a familiar face are all examples of object detection. Object detection is one of the core problems in computer vision. Before the success of convolutional neural networks (CNNs)~\cite{krizhevsky2012imagenet}, object detection is usually addressed by sliding window based methods~\cite{felzenszwalb2010object, viola2004robust} that apply classifiers on handcrafted features~\cite{dalal2005histograms, lowe2004distinctive, cinbis2013segmentation} extracted at all possible locations and scales of images. Recently, the fully convolutional neural network (FCN)~\cite{long2015fully} based methods~\cite{sermanet2013overfeat, erhan2014scalable, YOLO} bring a revolution to the field of object detection. These FCN frameworks also follow a sliding window fashion, but their end-to-end approach of learning model parameters and image features from scratch significantly improves detection performance. 

R-CNN~\cite{girshick2014rich, girshick2015fast} further improves the accruacy on object detection beyond FCN based methods. Conceptually, R-CNN contains two phases. The first phase uses region proposal methods to generate all the potential bounding box candidates in the image. Then the second phase applies a CNN classifier to distinguish different objects for every proposal. Although R-CNN becomes the new state-of-the-art system for general object detection~\cite{everingham2010pascal, russakovsky2014imagenet}, it is very hard to detect small objects~\cite{pepik2015holding} such as human faces and far-away cars, since the low resolution and lack of contexts in each candidate box significantly decrease the classification accuracy on them. Moreover, the two different stages in the R-CNN pipeline cannot be optimized jointly, leaving the trouble for applying end-to-end training on R-CNN. 

In this work, we focus on one question: To what extent can an one-stage FCN perform on object detection? To this end, we present a novel FCN based object detector, DenseBox, that does not require proposal generation and is able to be optimized end-to-end during training. Although similar to many existing sliding window fashion FCN detection frameworks~\cite{sermanet2013overfeat, erhan2014scalable, YOLO}, DenseBox is more carefully designed to detect objects under small scales and heavy occlusion. We train DenseBox and apply careful hard negative mining techniques to boostrap the detection performance. To make it even better, we further integrate landmark localization into the system through joint multi-task learning~\cite{bengio2013representation}. To verify the usefulness of landmark localization, we manually annotate a set of keypoints for the KITTI car detection dataset~\cite{Geiger2012CVPR} and will release annotation afterward. 

Our contribution is two-fold. First, we demonstrate that a single fully convolutional neural network, if designed and optimized carefully, can detect objects under different scales with heavy occlusion extremely accurately and efficiently. Second, we show that when incorporating with landmark localization through multi-task learning, DenseBox further improves object detection accuracy. We present experimental results on public benchmark datasets including MALF (Multi-Attribute Labeled Faces) face detection~\cite{faceevaluation15} and KITTI car detection~\cite{Geiger2012CVPR}, that indicate our DenseBox is the state-of-the-art system for face detection and car detection.
%As one of the core problems in computer vision, object detection has some significant breakthrough recent years after the widely applied deep convolutional neural networks. Before the success of convolutional neural networks, the best performing detectors in many benchmarks were based on a combination of handcrafted image feature such as HOG~\cite{dalal2005histograms,zhang2011boosted,yu2010object} , SIFT~\cite{lowe2004distinctive} , and the Fisher vector~\cite{cinbis2013segmentation} , etc. These systems such as deformable part-based models (DPM)~\cite{felzenszwalb2010object} use sliding window framework to apply classifier at every object location and scale. Recently, the convolutional neural network based methods such as R-CNN~\cite{girshick2014rich,girshick2015fast} bring a revolution on the field of object detection , providing a remarkable gain in detection accuracy compared to classic sliding window approaches. Conceptually, R-CNN contains two phases. First, region proposal methods are used to generate potential bounding boxes in the image. Then, a convolutional classifier is applied to each proposed bounding box. 

%However, the different stages in R-CNN pipeline cannot be optimized jointly, and to classify thousands of proposal bounding boxes of one image, it usually requires half a minute. The second issue has been solved in the latest incarnation of R-CNN, the Faster R-CNN~\cite{ren2015faster} which shares the convolutional feature computation among different regions. Then the proposal generation becomes the new bottleneck. Recently some methods try to solve the first issue by one of the following two ways: 1) The Faster-R-CNN trains a region proposal network shared with CNN classifier; 2) YOLO~\cite{YOLO}  presents a single network end-to-end optimized directly on detection performance, and Lenc et al.~\cite{LencV15} proposed a simplified SPP-CNN~\cite{} that does not need proposal generation. All of them focus on acceleration of testing, and developing an end-to-end framework for detection. 

%In this work, we focus on one question: To what extent can an one-stage CNN-based detection system perform? Although similar to YOLO~\cite{YOLO}, MultiBox~\cite{} and OverFeat~\cite{sermanet2013overfeat}, our system is more carefully designed for a set of specific problems such as face detection and car detection. Unlike general object detection in PASCAL VOC or ImageNet, the target objects like faces and cars could be very small but crucial to real world applications ({\em i.e.} self-driving car). However, general proposal based detection methods could fail due to the the small resolution of objects. Our system is designed end-to-end to detect objects over all possible locations and scales in an image. 

%To this end, we present a novel fully convolutional neural network based object detector, called DenseBox, that does not require proposal generation and is able to be optimized end-to-end during training. We further integrate landmark localization task into the system through multi-task learning, and demonstrate that landmark localization is helpful and crucial for object detection. Experimental results show that our method results in the state-of-the-art performance on MALF(Multi-Attribute Labelled Faces)~\cite{faceevaluation15} detection dataset and KITTI~\cite{Geiger2012CVPR} car detection dataset, suggesting that the purely fully convolutional networks for object detection can work very well when we design and train carefully. 
