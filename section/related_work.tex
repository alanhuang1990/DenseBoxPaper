\section{Related Work}

The literature on object detection is vast. Before the success of deep convolutional neural networks, the best performing detectors in many benchmarks are based on a combination of handcrafted image features such as HOG~\cite{dalal2005histograms}, SIFT~\cite{lowe2004distinctive}, Fisher Vector~\cite{cinbis2013segmentation}, etc. These systems such as deformable part-based models (DPMs)~\cite{felzenszwalb2010object, zhu2012face} use sliding window framework to apply classifier at every location and scale in an image.

The application of neural networks for detection tasks such as face detection also has a long history. The first work may date back to early in 1994 when Vaillant et al.\cite{vaillant1994original} proposed to train a convolutional neural network to detect face in image window. Later in 1996 and 1998 Rowley et al.\cite{rowley1998neural,rowley1998rotation} presented many neural network based face detection system to detect upright frontal face in image pyramid. There is no way to compare the performance of those ancient detectors with today’s detection systems on face detection benchmarks. Even so, they are still worth revisiting, as we find many similarities in design with our DenseBox. 

Several recent papers propose ways of using deep networks for locating class-specific or class-agnostic bounding boxes~\cite{sermanet2013overfeat, erhan2014scalable, YOLO}. In the OverFeat method~\cite{sermanet2013overfeat}, a 4-d output fc layer (for each or all classes) is trained to predict the box coordinates for the localization task (which assumes a single object). The fc layer is then turned into a conv layer for detecting multiple class- specific objects. The MultiBox methods~\cite{erhan2014scalable} generate region proposals from a network whose last fc layer simultaneously predicts multiple (e.g., 800) boxes, which are used for R-CNN~\cite{girshick2014rich} object detection. Their proposal network is applied on a single image or multiple large image crops (e.g., 224×224). We discuss OverFeat and MultiBox in more depth later in context with our method.

Currently, most state-of-the-art object detection approaches~\cite{ouyang2014deepid, li2015convolutional, erhan2014scalable,girshick2015fast} rely on R-CNN, which divides detection into two steps: salient object proposal generation and region proposal classification. Several recent works such as YOLO and Faster R-CNN have jointed region proposal generation with classifier in one stage or two stages. It is pointed out by~\cite{farfade2015multi} that R-CNN with general proposal methods designed for general object detection could results in inferior performance in detection task such as face detection, due to loss recall for small-sized faces and faces in complex appearance variations. They share similarities with our method, and we will discuss them with our method in more detail in later context.  

Besides the accuracy, computational effiency is also a key factor in object detection. To deal with this, shared computation of convolutions~\cite{sermanet2013overfeat, he2014spatial, ren2015faster, long2015fully} has been attracting increasing attention for efficient, yet accurate, visual recognition. The OverFeat paper~\cite{sermanet2013overfeat} computes convolutional features from an image pyramid for classification, localization, and detection. Adaptively-sized pooling~\cite{he2014spatial} on shared convolutional feature maps is proposed for efficient region-based object detection [7, 15] and semantic segmentation [2]. Fast R-CNN~\cite{ren2015faster} enables end-to-end training of adaptive pooling on shared convolutional features and shows compelling accuracy and speed.


Multi-task learning:
