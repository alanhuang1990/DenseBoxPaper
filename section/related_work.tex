\section{Related Work}

The literature on object detection is vast. Before the success of deep convolutional neural networks~\cite{krizhevsky2012imagenet}, the widely used detection systems are based on a combination of independent components. First, handcrafted image features such as HOG~\cite{dalal2005histograms}, SIFT~\cite{lowe2004distinctive}, and Fisher Vector~\cite{cinbis2013segmentation} are extracted at every location and scale of an image. Second, object models such as pictorial structure model (PSM)~\cite{felzenszwalb2005pictorial} and deformable part-based model (DPM)~\cite{felzenszwalb2010object, zhu2012face, yang2013articulated} allows object parts (e.g. head, torso, arms and legs of human) to deform with geometric constraints. Finally, a classifier such as boosting methods~\cite{viola2004robust}, linear SVM~\cite{dalal2005histograms}, latent SVM~\cite{felzenszwalb2010object}, or random forests~\cite{dollar2012crosstalk} decides whether a candidate window shall be detected as enclosing an object. 

%Before the success of deep convolutional neural networks, the best performing detectors in many benchmarks are based on a combination of handcrafted image features such as HOG~\cite{dalal2005histograms}, SIFT~\cite{lowe2004distinctive}, Fisher Vector~\cite{cinbis2013segmentation}, etc. These systems such as deformable part-based models (DPMs)~\cite{felzenszwalb2010object, zhu2012face} use sliding window framework to apply classifier at every location and scale in an image.

The application of neural networks for detection tasks such as face detection also has a long history. The first work may date back to early in 1994 when Vaillant et al.~\cite{vaillant1994original} proposed to train a convolutional neural network to detect face in image window. Later in 1996 and 1998 Rowley et al.~\cite{rowley1998neural,rowley1998rotation} presented neural network based face detection systems to detect upright frontal face in image pyramid. There is no way to compare the performance of those ancient detectors with today’s detection systems on face detection benchmarks. Even so, they are still worth revisiting, as we find many similarities in design with our DenseBox. 

Recently, several papers propose ways of using deep convolutional neural networks for locating class-specific or class-agnostic bounding boxes~\cite{sermanet2013overfeat, erhan2014scalable, YOLO}. OverFeat~\cite{sermanet2013overfeat} train a 4-d output layer (for each or all classes) to predict the box coordinates for the localization task. The fc layer is then turned into a convolutional layer for detecting multiple class-specific objects. MultiBox~\cite{erhan2014scalable} generate region proposals from a network whose last fc layer simultaneously predicts multiple (e.g., 800) boxes, which are used for R-CNN~\cite{girshick2014rich} object detection. Their proposal network is applied on a single image or multiple large image crops (e.g., 224×224). We discuss OverFeat and MultiBox in more depth later in context with our method.

Currently, most state-of-the-art object detection approaches~\cite{ouyang2014deepid, li2015convolutional, erhan2014scalable,girshick2015fast} rely on R-CNN, which divides detection into two steps: salient object proposal generation and region proposal classification. Several recent works such as YOLO and Faster R-CNN have jointed region proposal generation with classifier in one stage or two stages. It is pointed out by~\cite{farfade2015multi} that R-CNN with general proposal methods designed for general object detection could results in inferior performance in detection task such as face detection, due to loss recall for small-sized faces and faces in complex appearance variations. They share similarities with our method, and we will discuss them with our method in more detail in later context.  

Besides the accuracy, computational effiency is also crucial to real world detection applications. To deal with this, shared computation of convolutions~\cite{sermanet2013overfeat, he2014spatial, ren2015faster, long2015fully} has been attracting increasing attention for efficient, yet accurate, visual recognition. OverFeat~\cite{sermanet2013overfeat} computes convolutional features from an image pyramid for classification, localization, and detection. Adaptively-sized pooling~\cite{he2014spatial} on shared convolutional feature maps is proposed for efficient region-based object detection [7, 15] and semantic segmentation [2]. Fast R-CNN~\cite{ren2015faster} enables end-to-end training of adaptive pooling on shared convolutional features and shows compelling accuracy and speed.

Object detection is often involved with multi-tas learning such as pose estimation, semantic segmentation and landmark localization. Zhu et al.~\cite{2012face} propose a model for joint face detection, pose estimation and landmark localization 
Deep neural networks are also natural for integrating multi-task learning. Zhu et al.~\cite{2012face}
With the development of neural networks, multi-task learning is easily involved. Zhu et al.~\cite{zhu2012face} 
